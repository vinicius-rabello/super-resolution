{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import torch\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SinteticDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, directory, subwindow=None,\n",
    "                 transform=None, D=1, skip=1):\n",
    "        # D - Number of datas to retrieve. \n",
    "        # skip - interval between observations\n",
    "        # skip = 1 we get every observation\n",
    "        # skip = 2 every other observation\n",
    "\n",
    "        self.directory = directory\n",
    "        self.subwindow = subwindow  # Proportion of subwindow\n",
    "        self.files = [f for f in os.listdir(directory) if '.npy' in f]\n",
    "        self.D = D\n",
    "        self.skip = skip\n",
    "        self.Nx = (40*2)*2\n",
    "        self.Ny = (68*2)*2\n",
    "        self.valid_index = self.calcular_indices_validos()\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.valid_index)\n",
    "\n",
    "    def __getitem__(self, idx, subwindow=None):\n",
    "        idx = self.valid_index[idx]\n",
    "        file = idx//150\n",
    "        data = np.load(self.directory + \"/\" + self.files[file])\n",
    "        if file>0:\n",
    "            idx = idx-file*150\n",
    "        psi1 = data[0:150]\n",
    "        psi2 = data[150:]\n",
    "        psi1 = data[idx: idx+self.D*self.skip: self.skip]\n",
    "        psi2 = data[idx: idx+self.D*self.skip: self.skip]\n",
    "        if subwindow is None:\n",
    "            subwindow = self.subwindow\n",
    "\n",
    "        Ny_mesh, Nx_mesh = torch.meshgrid(torch.arange(self.Ny),torch.arange(self.Nx))\n",
    "        lat_idx, lon_idx = self.get_indices_from_proportion(Ny_mesh, Nx_mesh, subwindow)\n",
    "\n",
    "        psi1 = torch.tensor(psi1.reshape(psi1.shape[0],\n",
    "                                         self.Ny,self.Nx)[:,\n",
    "                                                     lat_idx[0]:lat_idx[1],\n",
    "                                                     lon_idx[0]:lon_idx[1]])\n",
    "        \n",
    "        psi2 = torch.tensor(psi2.reshape(psi2.shape[0],\n",
    "                                         self.Ny,self.Nx)[:,\n",
    "                                                     lat_idx[0]:lat_idx[1],\n",
    "                                                     lon_idx[0]:lon_idx[1]])\n",
    "                                                     \n",
    "        return torch.permute(torch.stack([psi1,psi2]), (1,0,2,3))\n",
    "        # [D, psis, NY, NX]\n",
    "        return self.prepare_tensors(u_velocity, v_velocity, ssh, mask, sliced_latitudes, sliced_longitudes)\n",
    "    \n",
    "\n",
    "    def get_indices_from_proportion(self, latitudes, longitudes, subwindow):\n",
    "        if subwindow:\n",
    "            lat_range = [int(subwindow[0][0] * len(latitudes)), int(subwindow[0][1] * len(latitudes))]\n",
    "            lon_range = [int(subwindow[1][0] * len(longitudes)), int(subwindow[1][1] * len(longitudes))]\n",
    "            return lat_range, lon_range\n",
    "        return [0, len(latitudes)], [0, len(longitudes)]\n",
    "    \n",
    "    \"\"\"\n",
    "    def prepare_tensors(self, u_velocity, v_velocity, ssh, mask, latitudes, longitudes):\n",
    "        u_tensor = torch.tensor(u_velocity.filled(0.0), dtype=torch.float32)\n",
    "        v_tensor = torch.tensor(v_velocity.filled(0.0), dtype=torch.float32)\n",
    "        ssh_tensor = torch.tensor(ssh.filled(0.0), dtype=torch.float32)\n",
    "        combined_tensor = torch.stack([u_tensor, v_tensor, ssh_tensor])\n",
    "        mask_tensor = torch.tensor(mask, dtype=torch.float32).unsqueeze(0)\n",
    "\n",
    "        # Creating tensors for the latitude and longitude slices\n",
    "        lat_tensor = torch.tensor(latitudes, dtype=torch.float32)\n",
    "        lon_tensor = torch.tensor(longitudes, dtype=torch.float32)\n",
    "\n",
    "        return mask_tensor, combined_tensor, lat_tensor, lon_tensor\n",
    "    \"\"\"\n",
    "    \n",
    "    def calcular_indices_validos(self):\n",
    "        block_size = 150\n",
    "        total_size = block_size*len(self.files)\n",
    "        \n",
    "        # Lista para armazenar os índices válidos\n",
    "        valid_indices = []\n",
    "        \n",
    "        # Percorre todos os índices possíveis\n",
    "        for start in range(total_size):\n",
    "            # Calcula os índices da sequência\n",
    "            indices = [start + i * self.skip for i in range(self.D)]\n",
    "            # print(indices)\n",
    "            # Verifica se o último índice é válido dentro do tamanho total\n",
    "            if indices[-1] >= total_size:\n",
    "                continue\n",
    "\n",
    "            # Determina o bloco do índice inicial e final\n",
    "            start_block = start // block_size\n",
    "            end_block = indices[-1] // block_size\n",
    "            # print('startbloc = ', start_block)\n",
    "            # print('end = ', end_block)\n",
    "            # Verifica se o bloco inicial e final são iguais\n",
    "            if start_block != end_block:\n",
    "                continue\n",
    "            \n",
    "            # Adiciona o índice inicial à lista de válidos se todas as condições forem satisfeitas\n",
    "            valid_indices.append(start)\n",
    "        \n",
    "        return valid_indices\n",
    "\n",
    "class ContiguousSinteticDatasetAutoregressive(SinteticDataset):\n",
    "    def __getitem__(self, idx, subwindow=None):\n",
    "        tensors = super().__getitem__(idx, subwindow)\n",
    "        x = tensors[-1]\n",
    "        y = {'y': tensors[:-1].reshape(-1,tensors.size(-2),tensors.size(-1))}\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotField2(ax, psi, Lx, Ly, filename):\n",
    "    x = np.linspace(0, Lx, psi.shape[0])\n",
    "    y = np.linspace(0, Ly, psi.shape[1])\n",
    "    X, Y = np.meshgrid(x, y)\n",
    "    psi = (psi + 2.5)/5\n",
    "    levels = np.linspace(0, 1, 5)\n",
    "    thresh_psi = np.digitize(psi.T, levels)\n",
    "    plt.imshow(thresh_psi, cmap='bwr')\n",
    "    # ax.set_cmap('bwr')\n",
    "    # contour = ax.contourf(X, Y, np.transpose(psi), levels=levels, cmap = 'bwr')\n",
    "    # plt.colorbar(contour, ax=ax) #, label='Value')\n",
    "\n",
    "    ax.axis('off')\n",
    "\n",
    "    plt.savefig(f\"test/{filename}.png\", format='png', bbox_inches='tight', pad_inches=0)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"../data/ocean\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 149/149 [00:00<00:00, 1090.27it/s]\n",
      "100%|██████████| 149/149 [00:00<00:00, 1115.68it/s]\n",
      "100%|██████████| 149/149 [00:00<00:00, 809.38it/s]\n",
      "100%|██████████| 149/149 [00:00<00:00, 1113.96it/s]\n",
      "100%|██████████| 149/149 [00:00<00:00, 1112.96it/s]\n",
      "100%|██████████| 149/149 [00:00<00:00, 1111.44it/s]\n",
      "100%|██████████| 149/149 [00:00<00:00, 1111.84it/s]\n",
      "100%|██████████| 149/149 [00:00<00:00, 1109.59it/s]\n",
      "100%|██████████| 149/149 [00:00<00:00, 1111.46it/s]\n",
      "100%|██████████| 149/149 [00:00<00:00, 1116.47it/s]\n",
      "100%|██████████| 149/149 [00:00<00:00, 1104.93it/s]\n",
      "100%|██████████| 149/149 [00:00<00:00, 1108.87it/s]\n",
      "100%|██████████| 149/149 [00:00<00:00, 1114.51it/s]\n",
      "100%|██████████| 149/149 [00:00<00:00, 1083.65it/s]\n",
      "100%|██████████| 149/149 [00:00<00:00, 1095.83it/s]\n",
      "100%|██████████| 149/149 [00:00<00:00, 904.45it/s] \n",
      "100%|██████████| 149/149 [00:00<00:00, 1121.50it/s]\n",
      "100%|██████████| 149/149 [00:00<00:00, 1115.78it/s]\n",
      "100%|██████████| 149/149 [00:00<00:00, 1114.32it/s]\n",
      "100%|██████████| 149/149 [00:00<00:00, 1124.97it/s]\n"
     ]
    }
   ],
   "source": [
    "data = ContiguousSinteticDatasetAutoregressive(path, D = 150)\n",
    "for i, file in enumerate(data):\n",
    "    file = file[1]['y']\n",
    "\n",
    "    psi1 = file[::2]\n",
    "    psi2 = file[1::2]\n",
    "\n",
    "    for j in tqdm(range(149)):\n",
    "        np.save('../ocean/data/raw/{i}_psi1_{j}.npy', psi1[j].T)\n",
    "        np.save('../ocean/data/raw/{i}_psi2_{j}.npy', psi2[j].T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
