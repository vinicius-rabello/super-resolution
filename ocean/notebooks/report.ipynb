{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.datasets as datasets\n",
    "from tqdm import tqdm\n",
    "from torch import nn\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "import sys\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "import pandas as pd\n",
    "\n",
    "# adding '../ocean/src/model/' to sys.path\n",
    "sys.path.append(os.path.abspath('../../ocean/src/model/'))\n",
    "\n",
    "from model import SuperResolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIM_X = 272 # input image is going to be resized to this size\n",
    "INPUT_DIM_Y = 160\n",
    "BATCH_SIZE = 1\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "def load_dataset(psi):\n",
    "    # loading the dataset\n",
    "    data_path = f'../data/dataset/{psi}/test_set' # setting path\n",
    "    # sequence of transformations to be done\n",
    "    transform = transforms.Compose([transforms.Resize((INPUT_DIM_X, INPUT_DIM_Y)),   # sequence of transformations to be done\n",
    "                                    transforms.Grayscale(num_output_channels=1), # on each image (resize, greyscale,\n",
    "                                    transforms.ToTensor()])                      # convert to tensor)\n",
    "\n",
    "    dataset = datasets.ImageFolder(root=data_path, transform=transform) # read data from folder\n",
    "    return dataset\n",
    "\n",
    "def load_model(DOWNGRADE_FACTOR, PSI):\n",
    "    # Initialize some constants\n",
    "    # if starting epoch is not 0, load from last trained model\n",
    "    model = SuperResolution().to(DEVICE)\n",
    "    model.load_state_dict(torch.load(f'../models/model_{PSI}_x{DOWNGRADE_FACTOR}_200'))\n",
    "    return model\n",
    "\n",
    "def get_average_psi(psi):\n",
    "    dataset = load_dataset(psi)\n",
    "    average_psi = np.zeros(shape=(272,160))\n",
    "    for i in range(len(dataset)):\n",
    "        x = dataset[i][0].numpy()[0]\n",
    "        average_psi += x\n",
    "    return average_psi/len(dataset)\n",
    "\n",
    "def mse(img1, img2):\n",
    "    err = np.sum((img1.astype(\"float\") - img2.astype(\"float\")) ** 2)\n",
    "    err /= float(img1.shape[0] * img1.shape[1])\n",
    "    return err\n",
    "\n",
    "def Ek(ypred, ytrue):\n",
    "  Ek = np.linalg.norm(ypred - ytrue)/np.max(np.absolute(ytrue))\n",
    "  return Ek\n",
    "\n",
    "def Acc(ypred, ytrue, average_psi):\n",
    "    den11 = np.sum(np.multiply(ypred - average_psi, ypred - average_psi))\n",
    "    den12 = np.sum(np.multiply(ytrue - average_psi,ytrue - average_psi))\n",
    "\n",
    "    den11 = max(1.0e-12,den11)\n",
    "    den12 = max(1.0e-12,den12)\n",
    "\n",
    "    Acc = np.sum(np.multiply(ypred - average_psi, ytrue - average_psi) )/(den11*den12)**0.5\n",
    "\n",
    "    return Acc\n",
    "\n",
    "def evaluate_prediction(x, DOWNGRADE_FACTOR, model, average_psi):\n",
    "    lr_x = F.interpolate(x.unsqueeze(0), size=(INPUT_DIM_X//DOWNGRADE_FACTOR, INPUT_DIM_Y//DOWNGRADE_FACTOR), mode='bilinear', align_corners=False)\n",
    "    lr_x = F.interpolate(lr_x, size=(INPUT_DIM_X, INPUT_DIM_Y), mode='bilinear', align_corners=False)\n",
    "\n",
    "    y = model(lr_x[0].to(DEVICE)).cpu()[0].detach().numpy()\n",
    "\n",
    "    mse_lr_hr = mse(lr_x.numpy()[0][0], x.numpy()[0])\n",
    "    mse_out_hr = mse(y, x.numpy()[0])\n",
    "    ssim_lr_hr = ssim(lr_x.numpy()[0][0], x.numpy()[0], data_range=1)\n",
    "    ssim_out_hr = ssim(y, x.numpy()[0], data_range=1)\n",
    "    ek_lr_hr = Ek(lr_x.numpy()[0][0], x.numpy()[0])\n",
    "    ek_out_hr = Ek(y, x.numpy()[0])\n",
    "    acc_lr_hr = Acc(lr_x.numpy()[0][0], x.numpy()[0], average_psi)\n",
    "    acc_out_hr = Acc(y, x.numpy()[0], average_psi)\n",
    "    return [mse_lr_hr, mse_out_hr, ssim_lr_hr, ssim_out_hr, ek_lr_hr, ek_out_hr, acc_lr_hr, acc_out_hr]\n",
    "\n",
    "# iterate over every image in test_set\n",
    "def metrics_dataframe():\n",
    "    metrics_df = []\n",
    "    for psi in ['psi1', 'psi2']:\n",
    "        dataset = load_dataset(psi)\n",
    "        average_psi = get_average_psi(psi)\n",
    "        for downgrade_factor in [4, 8, 16]:\n",
    "            metrics = []\n",
    "            model = load_model(downgrade_factor, psi)\n",
    "            for i in range(len(dataset)):\n",
    "                x = dataset[i][0]\n",
    "                evaluation = evaluate_prediction(x, downgrade_factor, model, average_psi)\n",
    "                metrics.append(evaluation)\n",
    "            metrics_df.append(np.array(metrics).mean(axis=0))\n",
    "    return metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/paulo-vinicius/super-resolution/venv/lib/python3.12/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "[Errno 36] File name too long: '../data/dataset/[[0.00240523 0.00239216 0.00226144 ... 0.00211765 0.0021634  0.00226144]\\n [0.0237451  0.02379739 0.02392811 ... 0.0234902  0.02347712 0.02349673]\\n [0.23594772 0.23567321 0.23556863 ... 0.23649674 0.23605883 0.23598693]\\n ...\\n [0.00484967 0.00477124 0.00467974 ... 0.00488889 0.00496078 0.00496078]\\n [0.03643137 0.03624183 0.03599347 ... 0.0365098  0.03653595 0.03666667]\\n [0.08369935 0.08350981 0.08332026 ... 0.08352288 0.0835817  0.08376471]]/test_set'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m metrics_df \u001b[38;5;241m=\u001b[39m \u001b[43mmetrics_dataframe\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m metrics_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(index\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpsi1 x4\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpsi1 x8\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpsi1 x16\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpsi2 x4\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpsi2 x8\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpsi2 x16\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m      3\u001b[0m              columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAverage MSE between LR and HR\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAverage MSE between Model Output and HR\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      4\u001b[0m                       \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAverage SSIM between LR and HR\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAverage SSIM between Model Output and HR\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      5\u001b[0m                       \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAverage EK between LR and HR\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAverage EK between Model Output and HR\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      6\u001b[0m                       \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAverage Acc between LR and HR\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAverage Acc between Model Output and HR\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m      7\u001b[0m              data\u001b[38;5;241m=\u001b[39mmetrics_df)\n\u001b[1;32m      9\u001b[0m metrics_df\u001b[38;5;241m.\u001b[39mto_excel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmetrics.xlsx\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[2], line 80\u001b[0m, in \u001b[0;36mmetrics_dataframe\u001b[0;34m()\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(dataset)):\n\u001b[1;32m     79\u001b[0m     x \u001b[38;5;241m=\u001b[39m dataset[i][\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m---> 80\u001b[0m     evaluation \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate_prediction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdowngrade_factor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maverage_psi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     81\u001b[0m     metrics\u001b[38;5;241m.\u001b[39mappend(evaluation)\n\u001b[1;32m     82\u001b[0m metrics_df\u001b[38;5;241m.\u001b[39mappend(np\u001b[38;5;241m.\u001b[39marray(metrics)\u001b[38;5;241m.\u001b[39mmean(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m))\n",
      "Cell \u001b[0;32mIn[2], line 65\u001b[0m, in \u001b[0;36mevaluate_prediction\u001b[0;34m(x, DOWNGRADE_FACTOR, model, average_psi)\u001b[0m\n\u001b[1;32m     63\u001b[0m ek_lr_hr \u001b[38;5;241m=\u001b[39m Ek(lr_x\u001b[38;5;241m.\u001b[39mnumpy()[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m], x\u001b[38;5;241m.\u001b[39mnumpy()[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m     64\u001b[0m ek_out_hr \u001b[38;5;241m=\u001b[39m Ek(y, x\u001b[38;5;241m.\u001b[39mnumpy()[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m---> 65\u001b[0m acc_lr_hr \u001b[38;5;241m=\u001b[39m \u001b[43mAcc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlr_x\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maverage_psi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m acc_out_hr \u001b[38;5;241m=\u001b[39m Acc(y, x\u001b[38;5;241m.\u001b[39mnumpy()[\u001b[38;5;241m0\u001b[39m], average_psi)\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m [mse_lr_hr, mse_out_hr, ssim_lr_hr, ssim_out_hr, ek_lr_hr, ek_out_hr, acc_lr_hr, acc_out_hr]\n",
      "Cell \u001b[0;32mIn[2], line 42\u001b[0m, in \u001b[0;36mAcc\u001b[0;34m(ypred, ytrue, psi)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mAcc\u001b[39m(ypred, ytrue, psi):\n\u001b[0;32m---> 42\u001b[0m     average_psi \u001b[38;5;241m=\u001b[39m \u001b[43mget_average_psi\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpsi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     43\u001b[0m     den11 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msum(np\u001b[38;5;241m.\u001b[39mmultiply(ypred \u001b[38;5;241m-\u001b[39m average_psi, ypred \u001b[38;5;241m-\u001b[39m average_psi))\n\u001b[1;32m     44\u001b[0m     den12 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msum(np\u001b[38;5;241m.\u001b[39mmultiply(ytrue \u001b[38;5;241m-\u001b[39m average_psi,ytrue \u001b[38;5;241m-\u001b[39m average_psi))\n",
      "Cell \u001b[0;32mIn[2], line 25\u001b[0m, in \u001b[0;36mget_average_psi\u001b[0;34m(psi)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_average_psi\u001b[39m(psi):\n\u001b[0;32m---> 25\u001b[0m     dataset \u001b[38;5;241m=\u001b[39m \u001b[43mload_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpsi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m     average_psi \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros(shape\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m272\u001b[39m,\u001b[38;5;241m160\u001b[39m))\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(dataset)):\n",
      "Cell \u001b[0;32mIn[2], line 14\u001b[0m, in \u001b[0;36mload_dataset\u001b[0;34m(psi)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# sequence of transformations to be done\u001b[39;00m\n\u001b[1;32m     10\u001b[0m transform \u001b[38;5;241m=\u001b[39m transforms\u001b[38;5;241m.\u001b[39mCompose([transforms\u001b[38;5;241m.\u001b[39mResize((INPUT_DIM_X, INPUT_DIM_Y)),   \u001b[38;5;66;03m# sequence of transformations to be done\u001b[39;00m\n\u001b[1;32m     11\u001b[0m                                 transforms\u001b[38;5;241m.\u001b[39mGrayscale(num_output_channels\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m), \u001b[38;5;66;03m# on each image (resize, greyscale,\u001b[39;00m\n\u001b[1;32m     12\u001b[0m                                 transforms\u001b[38;5;241m.\u001b[39mToTensor()])                      \u001b[38;5;66;03m# convert to tensor)\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m dataset \u001b[38;5;241m=\u001b[39m \u001b[43mdatasets\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mImageFolder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mroot\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransform\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# read data from folder\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m dataset\n",
      "File \u001b[0;32m~/super-resolution/venv/lib/python3.12/site-packages/torchvision/datasets/folder.py:328\u001b[0m, in \u001b[0;36mImageFolder.__init__\u001b[0;34m(self, root, transform, target_transform, loader, is_valid_file, allow_empty)\u001b[0m\n\u001b[1;32m    319\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m    320\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    321\u001b[0m     root: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    326\u001b[0m     allow_empty: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    327\u001b[0m ):\n\u001b[0;32m--> 328\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    329\u001b[0m \u001b[43m        \u001b[49m\u001b[43mroot\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    330\u001b[0m \u001b[43m        \u001b[49m\u001b[43mloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    331\u001b[0m \u001b[43m        \u001b[49m\u001b[43mIMG_EXTENSIONS\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mis_valid_file\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    332\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtransform\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    333\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtarget_transform\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtarget_transform\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    334\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_valid_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_valid_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    335\u001b[0m \u001b[43m        \u001b[49m\u001b[43mallow_empty\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_empty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    336\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    337\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimgs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msamples\n",
      "File \u001b[0;32m~/super-resolution/venv/lib/python3.12/site-packages/torchvision/datasets/folder.py:149\u001b[0m, in \u001b[0;36mDatasetFolder.__init__\u001b[0;34m(self, root, loader, extensions, transform, target_transform, is_valid_file, allow_empty)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m    139\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    140\u001b[0m     root: Union[\u001b[38;5;28mstr\u001b[39m, Path],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    146\u001b[0m     allow_empty: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    147\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    148\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(root, transform\u001b[38;5;241m=\u001b[39mtransform, target_transform\u001b[38;5;241m=\u001b[39mtarget_transform)\n\u001b[0;32m--> 149\u001b[0m     classes, class_to_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind_classes\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mroot\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    150\u001b[0m     samples \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmake_dataset(\n\u001b[1;32m    151\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mroot,\n\u001b[1;32m    152\u001b[0m         class_to_idx\u001b[38;5;241m=\u001b[39mclass_to_idx,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    155\u001b[0m         allow_empty\u001b[38;5;241m=\u001b[39mallow_empty,\n\u001b[1;32m    156\u001b[0m     )\n\u001b[1;32m    158\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloader \u001b[38;5;241m=\u001b[39m loader\n",
      "File \u001b[0;32m~/super-resolution/venv/lib/python3.12/site-packages/torchvision/datasets/folder.py:234\u001b[0m, in \u001b[0;36mDatasetFolder.find_classes\u001b[0;34m(self, directory)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfind_classes\u001b[39m(\u001b[38;5;28mself\u001b[39m, directory: Union[\u001b[38;5;28mstr\u001b[39m, Path]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[List[\u001b[38;5;28mstr\u001b[39m], Dict[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mint\u001b[39m]]:\n\u001b[1;32m    208\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Find the class folders in a dataset structured as follows::\u001b[39;00m\n\u001b[1;32m    209\u001b[0m \n\u001b[1;32m    210\u001b[0m \u001b[38;5;124;03m        directory/\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[38;5;124;03m        (Tuple[List[str], Dict[str, int]]): List of all classes and dictionary mapping each class to an index.\u001b[39;00m\n\u001b[1;32m    233\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 234\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfind_classes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdirectory\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/super-resolution/venv/lib/python3.12/site-packages/torchvision/datasets/folder.py:41\u001b[0m, in \u001b[0;36mfind_classes\u001b[0;34m(directory)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfind_classes\u001b[39m(directory: Union[\u001b[38;5;28mstr\u001b[39m, Path]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[List[\u001b[38;5;28mstr\u001b[39m], Dict[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mint\u001b[39m]]:\n\u001b[1;32m     37\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Finds the class folders in a dataset.\u001b[39;00m\n\u001b[1;32m     38\u001b[0m \n\u001b[1;32m     39\u001b[0m \u001b[38;5;124;03m    See :class:`DatasetFolder` for details.\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 41\u001b[0m     classes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m(entry\u001b[38;5;241m.\u001b[39mname \u001b[38;5;28;01mfor\u001b[39;00m entry \u001b[38;5;129;01min\u001b[39;00m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscandir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdirectory\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m entry\u001b[38;5;241m.\u001b[39mis_dir())\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m classes:\n\u001b[1;32m     43\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCouldn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt find any class folder in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdirectory\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mOSError\u001b[0m: [Errno 36] File name too long: '../data/dataset/[[0.00240523 0.00239216 0.00226144 ... 0.00211765 0.0021634  0.00226144]\\n [0.0237451  0.02379739 0.02392811 ... 0.0234902  0.02347712 0.02349673]\\n [0.23594772 0.23567321 0.23556863 ... 0.23649674 0.23605883 0.23598693]\\n ...\\n [0.00484967 0.00477124 0.00467974 ... 0.00488889 0.00496078 0.00496078]\\n [0.03643137 0.03624183 0.03599347 ... 0.0365098  0.03653595 0.03666667]\\n [0.08369935 0.08350981 0.08332026 ... 0.08352288 0.0835817  0.08376471]]/test_set'"
     ]
    }
   ],
   "source": [
    "metrics_df = metrics_dataframe()\n",
    "metrics_df = pd.DataFrame(index=['psi1 x4', 'psi1 x8', 'psi1 x16', 'psi2 x4', 'psi2 x8', 'psi2 x16'],\n",
    "             columns=['Average MSE between LR and HR','Average MSE between Model Output and HR',\n",
    "                      'Average SSIM between LR and HR', 'Average SSIM between Model Output and HR',\n",
    "                      'Average EK between LR and HR', 'Average EK between Model Output and HR',\n",
    "                      'Average Acc between LR and HR', 'Average Acc between Model Output and HR'],\n",
    "             data=metrics_df)\n",
    "\n",
    "metrics_df.to_excel('metrics.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_prediction(model, x, DOWNGRADE_FACTOR):\n",
    "    lr_x = F.interpolate(x.unsqueeze(0), size=(INPUT_DIM_X//DOWNGRADE_FACTOR, INPUT_DIM_Y//DOWNGRADE_FACTOR), mode='bilinear', align_corners=False)\n",
    "    lr_x = F.interpolate(lr_x, size=(INPUT_DIM_X, INPUT_DIM_Y), mode='bilinear', align_corners=False)\n",
    "\n",
    "    y = model(lr_x[0].to(DEVICE)).cpu()[0].detach().numpy()\n",
    "\n",
    "    return lr_x, y\n",
    "\n",
    "\n",
    "\n",
    "def plot_results_psi(psi, idx = None):\n",
    "    \n",
    "    dataset = load_dataset(psi)\n",
    "\n",
    "    # If idx is not provided, select a random index from the dataset\n",
    "    if not idx:\n",
    "        idx = np.random.choice(len(dataset))\n",
    "\n",
    "    # Create a figure with a grid of subplots (3 rows and 3 columns)\n",
    "    fig, axs = plt.subplots(3, 3, figsize = (5,8), tight_layout = True)\n",
    "    fig.suptitle(f\"Model trained on \")\n",
    "\n",
    "    # Transform the axes into a one-dimensional array for easier indexing\n",
    "    axs = np.array(axs).T.ravel()\n",
    "\n",
    "    i = 0\n",
    "    for downgrade_factor in (4, 8, 16):\n",
    "        model = load_model(downgrade_factor, psi)\n",
    "        x = dataset[idx][0]\n",
    "        lr_x, pred_x = model_prediction(model, x, downgrade_factor)\n",
    "    \n",
    "    # Display the low-resolution images, predictions, and original image in the subplots\n",
    "        axs[i].imshow(lr_x[0][0], cmap = \"bwr\")\n",
    "        axs[i+1].imshow(pred_x, cmap = \"bwr\")\n",
    "        axs[i+2].imshow(x[0], cmap = \"bwr\")\n",
    "        i += 3\n",
    "    \n",
    "    # Add explanatory text to plots\n",
    "    axs[0].set_title(\"x4 model\")\n",
    "    axs[3].set_title(\"x8 model\")\n",
    "    axs[6].set_title(\"x16 model\")\n",
    "    axs[0].text(-0.1, 0.5, \"Low resolution input\", va='center', ha='right', rotation=90, transform=axs[0].transAxes)\n",
    "    axs[1].text(-0.1, 0.5, \"High resolution output\", va='center', ha='right', rotation=90, transform=axs[1].transAxes)\n",
    "    axs[2].text(-0.1, 0.5, \"Original image\", va='center', ha='right', rotation=90, transform=axs[2].transAxes)\n",
    "\n",
    "\n",
    "    plt.setp(axs, xticks=[], yticks=[])\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_results_psi(\"psi1\")#, 568)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_results_psi(\"psi2\", 348)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
